{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just an outline in the beginning to decide upon the topic flows. \n",
    "\n",
    "# Covariance\n",
    "\n",
    "## Theory\n",
    "Here we describe the intuitive story behind the formula. Story ends up with deriving,\n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(X,Y) = \\dfrac{1}{N}\\sum_{i=1}^{N}(x-\\overline{x})(y - \\overline{y})\n",
    "$$\n",
    "\n",
    "Story inspired from and uses idea from [1](https://stats.stackexchange.com/questions/18058/how-would-you-explain-covariance-to-someone-who-understands-only-the-mean), [2](https://www.researchgate.net/profile/Yuli_Zhang/publication/261496020_Some_new_deformation_formulas_about_variance_and_covariance/links/54eda4c80cf25da9f7f1274e/Some-new-deformation-formulas-about-variance-and-covariance.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generalization\n",
    "\n",
    "Here, the formula is generalized to \n",
    "\n",
    "$$\n",
    "\\mathrm{Cov}(X,Y) = E[(X - \\mu_x)(Y - \\mu_Y)] = \n",
    "    \\begin{cases}\n",
    "       \\sum\\limits_{x}\\sum\\limits_{y}(x - \\overline{x})(y - \\overline{y})p(x,y) \\ \\ \\ \\ \\text{X,Y discrete} \\\\\n",
    "       \\int\\limits_{-\\infty}^{\\infty}\\int\\limits_{-\\infty}^{\\infty}(x - \\overline{x})(y - \\overline{y})f(x,y) \\ \\ \\ \\ \\text{X,Y continuous}\n",
    "    \\end{cases} \n",
    "$$\n",
    "\n",
    "Reference: Devore's Chapter 5.2. Page 206. Derive from general expectation of $h(X,Y)$ to above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Discrete: Ex 5.15 Devore Page 208"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation $\\rho$\n",
    "\n",
    "## Theory\n",
    "To intuitively justify,\n",
    "\n",
    "$$\n",
    " \\rho = \\mathrm{Corr(X,Y)} =  \\dfrac{\\mathrm{Cov}(X,Y)}{\\sigma_X\\sigma_Y} \\tag*{population correlation coefficient}\n",
    "$$\n",
    "\n",
    "References:  \n",
    "http://www.hawaii.edu/powerkills/UC.HTM#C2  \n",
    "https://www.youtube.com/watch?v=LyGKycYT2v0  \n",
    "http://jtdaugherty.github.io/posts/linear-algebra-2.html  \n",
    "https://en.wikipedia.org/wiki/Pearson_correlation_coefficient#Geometric_interpretation  \n",
    "https://www.whitman.edu/mathematics/calculus_online/section12.03.html  \n",
    "http://tutorial.math.lamar.edu/Classes/CalcII/DotProduct.aspx  \n",
    "\n",
    "\n",
    "## Derivation\n",
    "Here we extend the intuition. Take $(x,y)$ and $(\\mu_X, \\mu_Y)$ as two points of potential regression line $(y - \\mu_Y) = b(x - \\mu_X)$. Find $b$ using MLE. Assume $\\rho$ formula as above and then prove how the variation in dataset is reflected in $\\rho$ as part of the equation. Should end up with \n",
    "\n",
    "$$\n",
    "K(\\rho\\dfrac{\\sigma_Y}{\\sigma_X}) = \\sigma_Y^2(1 - \\rho^2)\n",
    "$$\n",
    "\n",
    "which then can be used to show variation of $\\rho$\n",
    "\n",
    "Reference: Hogg, Page 136 Chapter 4 Bivariate Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Discrete: Ex 5.18 Devore Page 210"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Samples and Population\n",
    "\n",
    "Note the formula is similar for both and present them to be aware that both exists.  \n",
    "\n",
    "$$\n",
    "r = \\dfrac{S_{XY}}{\\sqrt{S_{XX}}\\sqrt{S_{YY}}}  \\tag*{sample correlation coefficient}\n",
    "$$\n",
    "\n",
    "Reference: Devore, Page 508 Chapter 12.5 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note\n",
    "\n",
    "> Above is a point estimator. And for interval estimators, just like we did Confidence intervals and Hypothesis testing for 1 dimensional RV X earlier, this setup of 2 dimensional XY, calls for more complicated methods of confidence intervals and hypothesis testing.  \n",
    "\n",
    "> Independence implies zero correlation, but zero correlation does not necessarily imply independence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
